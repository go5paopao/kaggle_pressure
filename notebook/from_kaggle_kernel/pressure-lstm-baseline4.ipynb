{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:41.492432Z",
     "iopub.status.busy": "2021-09-28T08:50:41.492136Z",
     "iopub.status.idle": "2021-09-28T08:50:43.901509Z",
     "shell.execute_reply": "2021-09-28T08:50:43.900769Z",
     "shell.execute_reply.started": "2021-09-28T08:50:41.492382Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    CosineAnnealingLR,\n",
    "    ReduceLROnPlateau,\n",
    "    ExponentialLR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:43.908215Z",
     "iopub.status.busy": "2021-09-28T08:50:43.907693Z",
     "iopub.status.idle": "2021-09-28T08:50:43.912775Z",
     "shell.execute_reply": "2021-09-28T08:50:43.911957Z",
     "shell.execute_reply.started": "2021-09-28T08:50:43.908178Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_TPU = False\n",
    "EXP_DIR = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:43.914635Z",
     "iopub.status.busy": "2021-09-28T08:50:43.914242Z",
     "iopub.status.idle": "2021-09-28T08:50:43.924863Z",
     "shell.execute_reply": "2021-09-28T08:50:43.924084Z",
     "shell.execute_reply.started": "2021-09-28T08:50:43.914599Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:43.928321Z",
     "iopub.status.busy": "2021-09-28T08:50:43.927663Z",
     "iopub.status.idle": "2021-09-28T08:50:51.027295Z",
     "shell.execute_reply": "2021-09-28T08:50:51.026483Z",
     "shell.execute_reply.started": "2021-09-28T08:50:43.928284Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/ventilator-pressure-prediction/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/ventilator-pressure-prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.029459Z",
     "iopub.status.busy": "2021-09-28T08:50:51.029075Z",
     "iopub.status.idle": "2021-09-28T08:50:51.047697Z",
     "shell.execute_reply": "2021-09-28T08:50:51.046774Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.029427Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.050053Z",
     "iopub.status.busy": "2021-09-28T08:50:51.049648Z",
     "iopub.status.idle": "2021-09-28T08:50:51.062807Z",
     "shell.execute_reply": "2021-09-28T08:50:51.061786Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.049978Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_feature(train_df, test_df):\n",
    "    \n",
    "    def _make_feature_per_dataset(df):\n",
    "        u_out_change_time = df.loc[\n",
    "            df.groupby(\"breath_id\")[\"u_out\"].diff() == 1,\n",
    "            [\"breath_id\", \"time_step\"]\n",
    "        ]\n",
    "        u_out_change_time = u_out_change_time.rename(columns={\"time_step\": \"u_out_change_time_step\"})\n",
    "        df = df.merge(u_out_change_time, on=\"breath_id\", how=\"left\")\n",
    "        df[\"time_from_u_out_change\"] = df[\"time_step\"] - df[\"u_out_change_time_step\"]\n",
    "        df.drop([\"u_out_change_time_step\"], axis=1, inplace=True)\n",
    "\n",
    "        df[\"u_in_cumsum\"] = df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n",
    "        df[\"u_in_diff\"] = (df.groupby(\"breath_id\")[\"u_in\"].diff() / df.groupby(\"breath_id\")[\"time_step\"].diff()).fillna(0)\n",
    "        \n",
    "        df['area'] = df['time_step'] * df['u_in']\n",
    "        df['area'] = df.groupby('breath_id')['area'].cumsum()        \n",
    "        df['u_in_lag2'] = df.groupby(\"breath_id\")['u_in'].shift(2).fillna(0)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    train_df = _make_feature_per_dataset(train_df)\n",
    "    test_df = _make_feature_per_dataset(test_df)\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.064523Z",
     "iopub.status.busy": "2021-09-28T08:50:51.064227Z",
     "iopub.status.idle": "2021-09-28T08:50:51.075676Z",
     "shell.execute_reply": "2021-09-28T08:50:51.074972Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.064490Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_feature(train_df, valid_df, test_df):\n",
    "    \n",
    "    cols = [\n",
    "        \"u_in\",\n",
    "        \"u_in_cumsum\",\n",
    "        \"time_step\",\n",
    "        \"time_from_u_out_change\",\n",
    "        \"u_in_diff\",\n",
    "        #\"u_in_at_out1\",\n",
    "        #\"u_in_at_out0\",\n",
    "        #\"u_in_at_out1_cumsum\",\n",
    "        #\"u_in_at_out0_cumsum\",\n",
    "        \"area\",\n",
    "        \"u_in_lag2\"\n",
    "    ]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_df[cols] = scaler.fit_transform(train_df[cols])\n",
    "    valid_df[cols] = scaler.transform(valid_df[cols])\n",
    "    test_df[cols] = scaler.transform(test_df[cols])\n",
    "\n",
    "    #for c in normalize_cols:    \n",
    "    #    scaler = StandardScaler()\n",
    "    #    train_df[c] = scaler.fit_transform(train_df[c])\n",
    "    #    valid_df[c] = scaler.transform(valid_df[c])\n",
    "    #    test_df[c] = scaler.transform(test_df[c])\n",
    "    \n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.077478Z",
     "iopub.status.busy": "2021-09-28T08:50:51.077181Z",
     "iopub.status.idle": "2021-09-28T08:50:51.092490Z",
     "shell.execute_reply": "2021-09-28T08:50:51.091765Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.077444Z"
    }
   },
   "outputs": [],
   "source": [
    "class PressureDataset(Dataset):\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self, df, seq_features, is_train=True):\n",
    "        \n",
    "        self.ids = df[\"id\"].values\n",
    "        self.breath_ids = df[\"breath_id\"].unique()\n",
    "        self.seq_features = seq_features\n",
    "\n",
    "        self.r_dict = {\n",
    "            5: 0,\n",
    "            20: 1,\n",
    "            50: 2,\n",
    "        }\n",
    "        self.c_dict = {\n",
    "            10: 0,\n",
    "            20: 1,\n",
    "            50: 2,\n",
    "        }\n",
    "        \n",
    "        R_dict = df.groupby(\"breath_id\")[\"R\"].first()\n",
    "        self.R_dict = R_dict.map(self.r_dict).to_dict()\n",
    "        C_dict = df.groupby(\"breath_id\")[\"C\"].first()\n",
    "        self.C_dict = C_dict.map(self.c_dict).to_dict()\n",
    "        \n",
    "        self.seq_features_arr_dict = {}\n",
    "        for feat in self.seq_features:\n",
    "            self.seq_features_arr_dict[feat] = df.groupby(\"breath_id\")[feat].apply(lambda x: x.values).to_dict()\n",
    "\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.target_arr_dict = df.groupby(\"breath_id\")[\"pressure\"].apply(lambda x: x.values).to_dict()\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.breath_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        breath_id = self.breath_ids[idx]\n",
    "\n",
    "        r_value = self.R_dict[breath_id]\n",
    "        c_value = self.C_dict[breath_id]\n",
    "        \n",
    "        global_features = torch.tensor(\n",
    "            [r_value, c_value], dtype=torch.long\n",
    "        )\n",
    "        features = {\n",
    "            \"global\": global_features\n",
    "        }\n",
    "        for feat in self.seq_features:\n",
    "            features[feat] = torch.tensor(self.seq_features_arr_dict[feat][breath_id], dtype=torch.float)\n",
    " \n",
    "        if self.is_train:\n",
    "            target = torch.tensor(\n",
    "                self.target_arr_dict[breath_id],\n",
    "                dtype=torch.float\n",
    "            )\n",
    "            return features, target\n",
    "        else:\n",
    "            return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.094231Z",
     "iopub.status.busy": "2021-09-28T08:50:51.093907Z",
     "iopub.status.idle": "2021-09-28T08:50:51.109422Z",
     "shell.execute_reply": "2021-09-28T08:50:51.108724Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.094195Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_features, pred_len=80, seq_len=80, device=\"cpu\", n_hidden=128):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.seq_features = seq_features\n",
    "        self.seq_feature_len = len(seq_features)\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "\n",
    "        self.seq_linear = nn.Sequential(\n",
    "            nn.Linear(self.seq_feature_len, n_hidden),\n",
    "            nn.LayerNorm(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(n_hidden*2, n_hidden),\n",
    "            #nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.r_emb = nn.Embedding(\n",
    "            3, 8\n",
    "        )\n",
    "        self.c_emb = nn.Embedding(\n",
    "            3, 8\n",
    "        )\n",
    "\n",
    "        self.encoder_rnn = nn.LSTM(\n",
    "            num_layers=4,\n",
    "            input_size=n_hidden,\n",
    "            hidden_size=n_hidden,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        self.decoder_rnn_cell = nn.LSTMCell(\n",
    "            input_size=n_hidden,\n",
    "            hidden_size=n_hidden,\n",
    "        )\n",
    "        # self.decoder_out = nn.Linear(n_hidden*2 + 8*2, 1)  # lstm_hidden + id_embedding\n",
    "        self.decoder_out = nn.Sequential(\n",
    "            nn.Linear(n_hidden*2 + 8*2, n_hidden),\n",
    "            nn.LayerNorm(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )   \n",
    "\n",
    "    def __call__(self, features):\n",
    "        \n",
    "        batch_size = features[\"global\"].shape[0]\n",
    "        \n",
    "        # global\n",
    "        global_hidden = torch.cat([\n",
    "            self.r_emb(features[\"global\"][:, 0]),\n",
    "            self.c_emb(features[\"global\"][:, 1])\n",
    "        ], dim=-1)\n",
    "        \n",
    "        # sequence\n",
    "        seq_input = torch.cat([\n",
    "            features[f].unsqueeze(-1) for f in self.seq_features\n",
    "        ], dim=-1)  # (batchsize, seq_len, feature_size)\n",
    "        seq_hidden = self.seq_linear(seq_input)  # (batchsize, seq_len, 32)\n",
    "        \n",
    "        hidden, (h_n, c_n) = self.encoder_rnn(seq_hidden)        \n",
    "        hidden = torch.cat([\n",
    "            hidden, global_hidden.unsqueeze(1).repeat([1, self.pred_len, 1])\n",
    "        ], dim=-1)\n",
    "        \n",
    "        pred = self.decoder_out(hidden)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.111354Z",
     "iopub.status.busy": "2021-09-28T08:50:51.110874Z",
     "iopub.status.idle": "2021-09-28T08:50:51.120586Z",
     "shell.execute_reply": "2021-09-28T08:50:51.119872Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.111319Z"
    }
   },
   "outputs": [],
   "source": [
    "# debug\n",
    "if 0:\n",
    "    dataset = PressureDataset(train_df, is_train=True)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #num_workers=1,\n",
    "        #collate_fn=collate_fn,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    model = RNNModel()\n",
    "\n",
    "    for features, target in loader:\n",
    "        features = features\n",
    "        target = target\n",
    "        break\n",
    "\n",
    "    pred = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.121647Z",
     "iopub.status.busy": "2021-09-28T08:50:51.121462Z",
     "iopub.status.idle": "2021-09-28T08:50:51.132758Z",
     "shell.execute_reply": "2021-09-28T08:50:51.131969Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.121626Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, data_loader, optimizer, config, device, scaler=None):\n",
    "    # get batch data loop\n",
    "    epoch_loss = 0\n",
    "    epoch_data_num = len(data_loader.dataset)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for iter_i, (features, targets) in enumerate(data_loader):\n",
    "        # input\n",
    "        features = {k : v.to(device) for k, v in features.items()}\n",
    "        targets = targets.to(device)\n",
    "        batch_size = len(targets)\n",
    "\n",
    "        # zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            if scaler is not None:\n",
    "                with amp.autocast():\n",
    "                    preds = model(features)\n",
    "            else:\n",
    "                preds = model(features)\n",
    "                \n",
    "            preds = preds.view(-1)\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "            loss = loss_fn(preds, targets)\n",
    "            print(f\"\\rTrain: {iter_i*config.batch_size} / {epoch_data_num}\", end='')\n",
    "            if USE_TPU:\n",
    "                loss.backward()\n",
    "                xm.optimizer_step(optimizer)\n",
    "            elif scaler is not None:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss_per_data = epoch_loss / epoch_data_num\n",
    "    print(f\"\\r\", end=\"\")\n",
    "    print(\"\\r                         \")\n",
    "    return epoch_loss_per_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.134346Z",
     "iopub.status.busy": "2021-09-28T08:50:51.134079Z",
     "iopub.status.idle": "2021-09-28T08:50:51.149686Z",
     "shell.execute_reply": "2021-09-28T08:50:51.149014Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.134312Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid_one_epoch(model, loss_fn, data_loader, config, device):\n",
    "    # get batch data loop\n",
    "    epoch_loss = 0\n",
    "    epoch_data_num = len(data_loader.dataset)\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "\n",
    "    model.eval()\n",
    "    for iter_i, (features, targets) in enumerate(data_loader):\n",
    "        # input\n",
    "        features = {k : v.to(device) for k, v in features.items()}\n",
    "        targets = targets.to(device)\n",
    "        batch_size = len(features)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(features)\n",
    "            preds = preds.view(-1)\n",
    "            targets = targets.view(-1)\n",
    "            print(f\"\\rVal: {iter_i*config.batch_size} / {epoch_data_num}\", end='')\n",
    "\n",
    "        pred_list.append(preds.detach().cpu().numpy())\n",
    "        target_list.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    epoch_loss_per_data = epoch_loss / epoch_data_num\n",
    "    val_preds = np.concatenate(pred_list, axis=0)\n",
    "    val_targets = np.concatenate(target_list, axis=0)\n",
    "    print(f\"\\r\", end=\"\")\n",
    "    print(\"\\r                         \")\n",
    "    return epoch_loss_per_data, val_preds, val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.153677Z",
     "iopub.status.busy": "2021-09-28T08:50:51.153343Z",
     "iopub.status.idle": "2021-09-28T08:50:51.176794Z",
     "shell.execute_reply": "2021-09-28T08:50:51.176086Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.153644Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_run(train_df, valid_df, config, model_prefix=\"\", save_best_model=True, save_model=True):\n",
    "    \n",
    "    \n",
    "    set_seed(config.seed)\n",
    "    \n",
    "    if USE_TPU:\n",
    "        device = xm.xla_device()\n",
    "    else:\n",
    "        device = torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "    print(f\"train run device : {device}\")\n",
    "    \n",
    "    ###################################\n",
    "    # Model\n",
    "    ###################################\n",
    "    model = RNNModel(seq_features=config.seq_features, device=device)\n",
    "    model.to(device)\n",
    "\n",
    "    ###################################\n",
    "    # Make data\n",
    "    ###################################\n",
    "    train_dataset = PressureDataset(train_df, seq_features=config.seq_features, is_train=True)\n",
    "    valid_dataset = PressureDataset(valid_df, seq_features=config.seq_features, is_train=True)\n",
    "\n",
    "    # data loader    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    ##################\n",
    "    # Optimiizer\n",
    "    ##################\n",
    "    if USE_TPU:\n",
    "        lr = config.lr * xm.xrt_world_size()\n",
    "    else:\n",
    "        lr = config.lr\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    ##################\n",
    "    # lr scheduler\n",
    "    ##################\n",
    "    scheduler = config.SchedulerClass(\n",
    "        optimizer, **config.scheduler_params\n",
    "    )\n",
    "\n",
    "    ##################\n",
    "    # loss function\n",
    "    ##################\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    ###############################\n",
    "    # train epoch loop\n",
    "    ###############################\n",
    "    # iteration and loss count\n",
    "    val_score = 0\n",
    "    best_model_path = None\n",
    "    best_val_score = 10000\n",
    "    best_val_epoch = -1\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    valid_period = 1\n",
    "    \n",
    "    results_list = []\n",
    "    val_preds_list = []\n",
    "    old_model_save_path = None\n",
    "\n",
    "    scaler = amp.GradScaler() if config.use_fp16 else None\n",
    "    \n",
    "    val_calc_indices = valid_df[\"u_out\"] == 0\n",
    "\n",
    "    for epoch in range(config.n_epoch):\n",
    "        \n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # train loop\n",
    "        train_epoch_loss = train_one_epoch(model, loss_fn, train_loader, optimizer, config, device, scaler=scaler)\n",
    "\n",
    "        # valid loop\n",
    "        valid_epoch_loss, val_preds, val_targets = valid_one_epoch(model, loss_fn, valid_loader, config, device)\n",
    "\n",
    "        # calc metric\n",
    "        val_score = mean_absolute_error(val_targets[val_calc_indices], val_preds[val_calc_indices])\n",
    "        \n",
    "        t_epoch_finish = time.time()\n",
    "        elapsed_time = t_epoch_finish - t_epoch_start\n",
    "\n",
    "        # learning rate step\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(valid_epoch_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        # save results\n",
    "        results = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"lr\": lr,\n",
    "            \"train_loss\": train_epoch_loss,\n",
    "            \"mae\": val_score\n",
    "        }\n",
    "        \n",
    "        results_list.append(results)\n",
    "\n",
    "        print(f\"\\r\", end=\"\")\n",
    "        pprint(results)\n",
    "        \n",
    "        val_preds_list.append(val_preds)\n",
    "\n",
    "        if val_score < best_val_score:\n",
    "            best_val_score = val_score\n",
    "            best_val_epoch = epoch\n",
    "\n",
    "            if save_best_model:\n",
    "               \n",
    "                if old_model_save_path is not None and old_model_save_path.exists():\n",
    "                    os.remove(old_model_save_path)\n",
    "                \n",
    "                model_save_path = EXP_DIR / f\"{model_prefix}best-checkpoint-{str(epoch).zfill(3)}epoch.bin\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                }, model_save_path)\n",
    "                \n",
    "                old_model_save_path = model_save_path\n",
    "                best_model_path = model_save_path\n",
    "\n",
    "        if epoch == config.n_epoch -1 and save_model:\n",
    "            model_save_path = EXP_DIR / f\"{model_prefix}last-checkpoint.bin\"\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'epoch': epoch,\n",
    "            }, model_save_path)\n",
    "\n",
    "    return best_val_score, results_list, val_preds_list, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.178934Z",
     "iopub.status.busy": "2021-09-28T08:50:51.178445Z",
     "iopub.status.idle": "2021-09-28T08:50:51.193256Z",
     "shell.execute_reply": "2021-09-28T08:50:51.192340Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.178896Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_predict(test_df, model_path):\n",
    "    \n",
    "    set_seed(config.seed)\n",
    "    \n",
    "    if USE_TPU:\n",
    "        device = xm.xla_device()\n",
    "    else:\n",
    "        device = torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "    ###################################\n",
    "    # Model\n",
    "    ###################################\n",
    "    model = RNNModel(seq_features=config.seq_features, device=device)\n",
    "    model.to(device)\n",
    "    \n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            model_path,\n",
    "            map_location=lambda storage,loc: storage\n",
    "        )[\"model_state_dict\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    ###################################\n",
    "    # Dataset & Dataloader\n",
    "    ###################################\n",
    "    test_dataset = PressureDataset(test_df, seq_features=config.seq_features, is_train=False)\n",
    "\n",
    "    # data loader    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=False,\n",
    "    )    \n",
    "\n",
    "    ###################################\n",
    "    # Inference\n",
    "    ###################################\n",
    "\n",
    "    pred_list = []\n",
    "    epoch_data_num = len(test_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    for iter_i, features in enumerate(test_loader):\n",
    "        # input\n",
    "        features = {k : v.to(device) for k, v in features.items()}\n",
    "        batch_size = len(features)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(features)\n",
    "            preds = preds.view(-1)\n",
    "            print(f\"\\rTest: {iter_i*config.batch_size} / {epoch_data_num}\", end='')\n",
    "\n",
    "        pred_list.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    test_preds = np.concatenate(pred_list, axis=0)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.195147Z",
     "iopub.status.busy": "2021-09-28T08:50:51.194758Z",
     "iopub.status.idle": "2021-09-28T08:50:51.205473Z",
     "shell.execute_reply": "2021-09-28T08:50:51.204531Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.195111Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 2021\n",
    "    \n",
    "    num_workers = 4\n",
    "    batch_size = 128\n",
    "    n_epoch = 150\n",
    "    lr = 5e-3\n",
    "\n",
    "    SchedulerClass = CosineAnnealingLR\n",
    "    scheduler_params = dict(\n",
    "        T_max=150,\n",
    "        eta_min=1e-5\n",
    "    )\n",
    "    n_cv_fold = 5    \n",
    "    use_fp16 = False\n",
    "    \n",
    "    seq_features = [\n",
    "        \"u_in\",\n",
    "        \"u_out\",\n",
    "        \"time_from_u_out_change\",\n",
    "        \"u_in_cumsum\",\n",
    "        \"u_in_diff\",\n",
    "        #\"u_in_at_out1\",\n",
    "        #\"u_in_at_out0\",\n",
    "        #\"u_in_at_out1_cumsum\",\n",
    "        #\"u_in_at_out0_cumsum\",\n",
    "        \"area\",\n",
    "        \"u_in_lag2\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:50:51.207401Z",
     "iopub.status.busy": "2021-09-28T08:50:51.206953Z",
     "iopub.status.idle": "2021-09-28T08:52:25.624332Z",
     "shell.execute_reply": "2021-09-28T08:52:25.623560Z",
     "shell.execute_reply.started": "2021-09-28T08:50:51.207339Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = GroupKFold(n_splits=config.n_cv_fold)\n",
    "oof_preds = np.zeros(len(train_df))\n",
    "test_preds = np.zeros(len(test_df))\n",
    "importance_list = []\n",
    "\n",
    "train_df, test_df = make_feature(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T08:52:25.626079Z",
     "iopub.status.busy": "2021-09-28T08:52:25.625814Z",
     "iopub.status.idle": "2021-09-28T09:35:50.575912Z",
     "shell.execute_reply": "2021-09-28T09:35:50.574795Z",
     "shell.execute_reply.started": "2021-09-28T08:52:25.626044Z"
    }
   },
   "outputs": [],
   "source": [
    "model_num = 0\n",
    "for fold_ix, (trn_idx, val_idx) in enumerate(folds.split(train_df, groups=train_df[\"breath_id\"])):\n",
    "    print(f\"Fold {fold_ix}\")\n",
    "    \n",
    "    _train_df = train_df.iloc[trn_idx].reset_index(drop=True)\n",
    "    _valid_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    _train_df, _valid_df, _test_df = normalize_feature(_train_df, _valid_df, test_df.copy())\n",
    "    \n",
    "    best_val_score, results_list, val_preds_list, best_model_path = train_run(\n",
    "        _train_df, _valid_df,\n",
    "        config, model_prefix=f\"fold{fold_ix}\", save_best_model=True, save_model=True\n",
    "    )\n",
    "    model_num += 1\n",
    "    \n",
    "    test_preds += test_predict(_test_df, best_model_path)\n",
    "    \n",
    "    if fold_ix >= 0:\n",
    "        break\n",
    "    \n",
    "test_preds = test_preds / model_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-28T09:35:50.577214Z",
     "iopub.status.idle": "2021-09-28T09:35:50.577938Z",
     "shell.execute_reply": "2021-09-28T09:35:50.577717Z",
     "shell.execute_reply.started": "2021-09-28T09:35:50.577675Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-28T09:35:50.579231Z",
     "iopub.status.idle": "2021-09-28T09:35:50.579895Z",
     "shell.execute_reply": "2021-09-28T09:35:50.579664Z",
     "shell.execute_reply.started": "2021-09-28T09:35:50.579640Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input/ventilator-pressure-prediction/sample_submission.csv\")\n",
    "sub_df[\"pressure\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-28T09:35:50.581317Z",
     "iopub.status.idle": "2021-09-28T09:35:50.581790Z",
     "shell.execute_reply": "2021-09-28T09:35:50.581570Z",
     "shell.execute_reply.started": "2021-09-28T09:35:50.581548Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
